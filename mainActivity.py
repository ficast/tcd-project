# A . Elabora√ß√£o de um conjunto de scripts e fun√ß√µes em Python, NumPy e SciPy para realizar as tarefas de prepara√ß√£o dos dados e Feature Engineering 

# X Crie um script e grave-o com o nome ‚ÄòmainActivity.py‚Äô. Este script ser√° utilizado na chamada de todas as fun√ß√µes indicadas abaixo.

# %%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
print("Ambiente configurado com sucesso!")
print(f"NumPy version: {np.__version__}")
print(f"Pandas version: {pd.__version__}")


# Descarregue os dados do site https://github.com/spl-icsforth/FORTH_TRACE_DATASET. 
# üñÆ Elabore uma rotina que carregue os dados relativos a um indiv√≠duo e os devolva num Array NumPy. 


# Cada ficheiro CSV segue o formato seguinte:

# Column1: Device ID
# Column2: accelerometer x
# Column3: accelerometer y
# Column4: accelerometer z
# Column5: gyroscope x
# Column6: gyroscope y
# Column7: gyroscope z
# Column8: magnetometer x
# Column9: magnetometer y
# Column10: magnetometer z
# Column11: Timestamp
# Column12: Activity Label

# Table 1: LOCATIONS
# 1 Left Wrist
# 2 Right Wrist
# 3 Torso
# 4 Right Thigh
# 5 Left Ankle

# Table 2: ACTIVITY LABELS
# (Arrows (->) indicate transitions between activities)

# 1 stand
# 2 sit
# 3 sit and talk
# 4 walk
# 5 walk and talk
# 6 climb stairs (up/down)
# 7 climb stairs (up/down) and talk
# 8 stand -> sit
# 9 sit -> stand
# 10 stand -> sit and talk
# 11 sit and talk -> stand
# 12 stand -> walk
# 13 walk -> stand
# 14 stand -> climb stairs (up/down), stand -> climb stairs (up/down) and talk
# 15 climb stairs (up/down) -> walk
# 16 climb stairs (up/down) and talk -> walk and talk


# path: ./FORTH_TRACE_DATASET/part0

# %%
def load_data(file_path):
	# Carregar os dados do ficheiro CSV para um DataFrame do Pandas
	df = pd.read_csv(file_path)
	df.columns = ['Device ID', 'accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'mag_x', 'mag_y', 'mag_z', 'Timestamp', 'Activity Label']
	# Converter o DataFrame para um Array NumPy
	# data_array = df.to_numpy()
	return df

# %%
# Carregar os dados de um indiv√≠duo (exemplo)
file_path = './FORTH_TRACE_DATASET/part0/part0dev1.csv'  # Substitua pelo caminho do

df = load_data(file_path)
# add headers
df.tail()


# %%
# Carregar todos os dados de um participante
base_path='./FORTH_TRACE_DATASET/'

def load_all_data(participant_id):
	df_final = pd.DataFrame()

	for part in range(1, 6):  # part1 a part5
		part_folder = f'part{participant_id}'
		file_path = f'{base_path}{part_folder}/{part_folder}dev{part}.csv'
		try:
			df = load_data(file_path)
			df_final = pd.concat([df_final, df], ignore_index=True)
		except FileNotFoundError:
			pass
	return df_final

# example
df_all = load_all_data(0)
print(f"Total de amostras carregadas: {len(df_all)}")
# df_all.tail()

# %%
# Carregar em um s√≥ dataframe todos os participantes de 0 a 14

def load_all_participants():
	df_final = pd.DataFrame()

	for participant_id in range(0, 15):  # part0 a part14
		df_participant = load_all_data(participant_id)
		# Criar coluna 'Participant ID' e definir como primeira coluna
		df_participant['Participant ID'] = participant_id
		cols = df_participant.columns.tolist()
		cols = ['Participant ID'] + [col for col in cols if col != 'Participant ID']
		df_participant = df_participant[cols]

		df_final = pd.concat([df_final, df_participant], ignore_index=True)
	return df_final

# example
df_all_participants = load_all_participants()
print(f"Total de amostras carregadas de todos os participantes: {len(df_all_participants)}")

# %%
df_all_participants.tail()

# %%
df_all_participants.head()

# %%
# Export CSV
df_all_participants.to_csv('all_participants_data.csv', index=False)

# %%
#Load from CSV
df_all_participants = pd.read_csv('all_participants_data.csv')
print(df_all_participants.head())


# %%
def plot_boxplot_by_activity(df, variable):
	plt.figure(figsize=(12, 6))
	df.boxplot(column=variable, by='Activity Label', grid=False)
	plt.title(f'Boxplot of {variable} by Activity Label')
	plt.suptitle('')
	plt.xlabel('Activity Label')
	plt.ylabel(variable)
	plt.show()

# %%
#Seaborn version of plot_boxplot_by_activity
import seaborn as sns
def plot_boxplot_by_activity_seaborn(df, variable):
	plt.figure(figsize=(12, 6))
	sns.boxplot(x='Activity Label', y=variable, data=df)
	plt.title(f'Boxplot of {variable} by Activity Label')
	plt.xlabel('Activity Label')
	plt.ylabel(variable)
	plt.show()

# Exemplo de uso
# Calcular o m√≥dulo do vector de acelera√ß√£o
df_all_participants['accel_magnitude'] = np.sqrt(df_all_participants['accel_x']**2 + df_all_participants['accel_y']**2 + df_all_participants['accel_z']**2)

# Calcular o m√≥dulo do vector de girosc√≥pio
df_all_participants['gyro_magnitude'] = np.sqrt(df_all_participants['gyro_x']**2 + df_all_participants['gyro_y']**2 + df_all_participants['gyro_z']**2)

# Calcular o m√≥dulo do vector de magnet√≥metro
df_all_participants['magneto_magnitude'] = np.sqrt(df_all_participants['mag_x']**2 + df_all_participants['mag_y']**2 + df_all_participants['mag_z']**2)

# An√°lise e tratamento de Outliers: o objectivo ser√° identificar e tratar outliers no dataset usando diferentes abordagens univari√°vel e multivari√°vel.  Para o efeito iremos os m√≥dulos dos vectores acelera√ß√£o, girosc√≥pio e magnet√≥metro. 
# Seja o vector acelera√ß√£o, girosc√≥pio e magnet√≥metro. O respectivo m√≥dulo √© determinado recorrendo:

# üñÆ Elabore uma rotina que apresente simultaneamente o boxplot de cada atividade (coluna 12 ‚Äì eixo horizontal)  
# relativo a todos os sujeitos e a uma das seguintes vari√°veis transformadas: m√≥dulo do vector de acelera√ß√£o, 
# m√≥dulo do vector de girosc√≥pio e m√≥dulo do vector de magnet√≥metro). Sugere-se o uso da biblioteca matplotlib. 
plot_boxplot_by_activity_seaborn(df_all_participants, 'accel_magnitude')
plot_boxplot_by_activity_seaborn(df_all_participants, 'gyro_magnitude')
plot_boxplot_by_activity_seaborn(df_all_participants, 'magneto_magnitude')

#Analise e comente a densidade de Outliers existentes no dataset transformado, 
# isto √©, nos m√≥dulos dos vectores acelera√ß√£o, girosc√≥pio e magnet√≥metro 
# para cada atividade. Observe que a densidade √© determinada recorrendo
# d = no/nr * 100
# em que no √© o n√∫mero de pontos classificados como outliers e nr √© o n√∫mero total de pontos.

# %%
def calculate_outlier_density(df, variable):
	# Calcular Q1, Q3 e IQR
	Q1 = df[variable].quantile(0.25)
	Q3 = df[variable].quantile(0.75)
	IQR = Q3 - Q1

	# Definir limites para outliers
	lower_bound = Q1 - 1.5 * IQR
	upper_bound = Q3 + 1.5 * IQR

	# Identificar outliers
	outliers = df[(df[variable] < lower_bound) | (df[variable] > upper_bound)]
	no = len(outliers)
	nr = len(df)
	density = (no / nr) * 100 if nr > 0 else 0
	return no, nr, density

# Uso
variables = ['accel_magnitude', 'gyro_magnitude', 'magneto_magnitude']
for var in variables:
	no, nr, density = calculate_outlier_density(df_all_participants, var)
	print(f'Variable: {var}, Outliers: {no}, Total: {nr}, Density: {density:.2f}%')



# Dado que a accel_magnitude tem uma densidade de outliers significativamente maior,
# vamos mudar o m√©todo de detec√ß√£o de outliers para essa vari√°vel, dado que para 
# esse tipo espec√≠fico de sensor pode ser necess√°rio limites mais flex√≠veis.


# %%
# üñÆ Escreva uma rotina que receba um Array de amostras de uma vari√°vel e identifique os outliers 
# usando o teste Z-Score para um k vari√°vel (par√¢metro de entrada).

def detect_outliers_z_score(data, k):
	mean = np.mean(data)
	std_dev = np.std(data)
	z_scores = (data - mean) / std_dev
	outliers = np.where(np.abs(z_scores) > k)[0]
	return outliers, z_scores


# Exemplo de uso

variables = ['accel_magnitude', 'gyro_magnitude', 'magneto_magnitude']

for var in variables:
	data = df_all_participants[var].values
	k_values = [3, 3.5, 4]
	for k in k_values:
		outliers, z_scores = detect_outliers_z_score(data, k)
		print(f'Variable: {var}, k={k}: Outliers detected: {len(outliers)}')


# üñé Usando o Z-score implementado assinale todos as amostras consideradas outliers nos 
# m√≥dulos dos vectores de acelera√ß√£o, girosc√≥pio e magnet√≥metro. 
# Apresente plots em que estes pontos surgem a vermelho enquanto os restantes surgem a azul.
#  Use k=3, 3.5 e 4.

# %%
# use seaborn for better plots, let's plot all three k for each variable in the same plot
# x axis is the activity label, y axis is the variable value
# blue points are normal, red points are outliers, use pastel colors
# for each variavle plot all three k values in the same plot side by side

#based on this one:

# def plot_boxplot_by_activity_seaborn(df, variable):
# 	plt.figure(figsize=(12, 6))
# 	sns.boxplot(x='Activity Label', y=variable, data=df)
# 	plt.title(f'Boxplot of {variable} by Activity Label')
# 	plt.xlabel('Activity Label')
# 	plt.ylabel(variable)
# 	plt.show()

import seaborn as sns
def plot_outliers_by_activity_seaborn(df, variable, k_values):
	plt.figure(figsize=(18, 6))
	for i, k in enumerate(k_values):
		plt.subplot(1, len(k_values), i + 1)
		data = df[variable].values
		outliers, z_scores = detect_outliers_z_score(data, k)
		df['Outlier'] = 'Normal'
		df.loc[outliers, 'Outlier'] = 'Outlier'
		sns.scatterplot(x='Activity Label', y=variable, hue='Outlier', data=df, palette={'Normal': 'blue', 'Outlier': 'red'}, alpha=0.5)
		plt.title(f'Outliers in {variable} (k={k})')
		plt.xlabel('Activity Label')
		plt.ylabel(variable)
		plt.legend()
	plt.tight_layout()
	plt.show()

variables = ['accel_magnitude', 'gyro_magnitude', 'magneto_magnitude']
k_values = [3, 3.5, 4]
for var in variables:
	plot_outliers_by_activity_seaborn(df_all_participants, var, k_values)


# %%
# Plotar a distribui√ß√£o de cada variavel
def plot_distribution(df, variable):
	plt.figure(figsize=(10, 6))
	sns.histplot(df[variable], bins=50, kde=True)
	plt.title(f'Distribution of {variable}')
	plt.xlabel(variable)
	plt.ylabel('Frequency')
	plt.show()

for var in variables:
	plot_distribution(df_all_participants, var)


# üñé Compare e discuta os resultados obtidos em 3.1 e 3.4.


# Dados:

# Variable: accel_magnitude, Outliers: 1103326, Total: 3930798, Density: 28.07%
# Variable: gyro_magnitude, Outliers: 160794, Total: 3930798, Density: 4.09%
# Variable: magneto_magnitude, Outliers: 174273, Total: 3930798, Density: 4.43%

# Variable: accel_magnitude, k=3: Outliers detected: 85688
# Variable: accel_magnitude, k=3.5: Outliers detected: 57721
# Variable: accel_magnitude, k=4: Outliers detected: 40641
# Variable: gyro_magnitude, k=3: Outliers detected: 72113
# Variable: gyro_magnitude, k=3.5: Outliers detected: 42708
# Variable: gyro_magnitude, k=4: Outliers detected: 23096
# Variable: magneto_magnitude, k=3: Outliers detected: 18698
# Variable: magneto_magnitude, k=3.5: Outliers detected: 6631
# Variable: magneto_magnitude, k=4: Outliers detected: 3063


# üñÆ Elabore uma rotina que implemente o algoritmo K-means para n (valor de entrada) clusters.
# üñé Determine os outliers no dataset transformado usando o  k-means. Experimente k clusters igual ao n√∫mero de labels e compare com os resultados obtidos em 3.4. Ilustre graficamente os resultados usando plots 3D.  
# B√≥nus: poder√° realizar um estudo an√°logo usando o algoritmo DBSCAN (sugere-se que recorra √† biblioteca sklearn) 

# üñÆ Implemente uma rotina que injete ouliers com uma densidade igual ou superior a x% nas amostras de vari√°vel fornecida. Para o efeito dever√°:
# A calcular a densidade de outliers existente no Array fornecido com nr pontos; observe que a densidade d √© obtida por

# em que


# Se a densidade d for inferior a x, ent√£o dever√° sortear  (x-d)% dos pontos n√£o outliers de forma aleat√≥ria e para cada ponto selecionado dever√° transform√°-lo tal que
 
# em que Œº e œÉ representam, respectivamente, os valores m√©dio e o desvio padr√£o da amostra,  k √© o limite especificado no ponto 3.3, s‚àà{-1,1} √© uma vari√°vel escolhida de forma aleat√≥ria usando uma distribui√ß√£o uniforme e q √© uma vari√°vel aleat√≥ria uniforme no intervalo q ‚àà [0,z[ em que z √© a amplitude m√°xima do outlier relativamente a Œº¬±kœÉ.

# üñÆ Elabore uma rotina que determine o modelo linear de ordem p. Para o efeito, a sua rotina dever√° receber n amostras de treino de um vector de dimens√£o p , isto √©, (xi,1, xi,2, xi,2, ... , xi,p) e a respectiva sa√≠da yi. A sua rotina dever√° determinar o melhor vector de pesos Œ≤ tal que 

# üñé Determine o modelo linear para o m√≥dulo acelera√ß√£o usando uma janela com p valores anteriores. Usando a rotina desenvolvida no ponto 3.9 injete 10% de outliers no m√≥dulo da acelera√ß√£o. Elimine esses outliers e substitua-os pelos valores previstos pelo modelo linear. Analise o erro de predi√ß√£o apresentando i) a distribui√ß√£o do erro e ii) exemplos de plots contendo o valor previsto e real. Determine o melhor p para o seu modelo.
# üñé Repita 3.10 usando uma janela de dimens√£o p centrada no instante a prever. Dever√° usar n√£o s√≥ os p/2 valores anteriores e seguintes da vari√°vel que pretende prever bem como das restantes vari√°veis dispon√≠veis (m√≥dulos dispon√≠veis). Compare com os resultados obtidos em 3.10.

# Extra√ß√£o de informa√ß√£o caracter√≠stica: o objectivo ser√° comprimir o espa√ßo do problema, extraindo informa√ß√£o caracter√≠stica discriminante que permita implementar solu√ß√µes eficazes do problema de classifica√ß√£o.

# üñé Usando as vari√°veis aplicadas na al√≠nea 3.1, determine a signific√¢ncia estat√≠sticas dos seus valores m√©dios na diferentes atividades. Observe que poder√° aferir a gaussianidade da distribui√ß√£o usando, por exemplo, o teste Kolmogorov-Smirnov (vide documenta√ß√£o do SciPy). Para rever a escolha de testes estat√≠sticos sugere-se a refer√™ncia: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881615/ .   Comente.
# üñÆ Desenvolva as rotinas necess√°rias √† extra√ß√£o do feature set temporal e espectral sugerido no artigo  https://pdfs.semanticscholar.org/8522/ce2bfce1ab65b133e411350478183e79fae7.pdf. Para o efeito dever√°:
# Ler o artigo e identificar o conjunto de features temporais e espectrais identificadas por estes autores
# Para cada feature dever√° elaborar uma rotina para a respectiva extra√ß√£o 
# Usando as rotinas elaboradas no item anterior, dever√° escrever o c√≥digo necess√°rio para extrair o vetor de features em cada instante.  
# Nota: Poder√° usar as bibliotecas NumPy e SciPy. Qualquer outra biblioteca dever√° ser identificada. 

# üñÆ Desenvolva o c√≥digo necess√°rio para implementar o PCA de um feature set.
# üñé Determine a import√¢ncia de cada vetor na explica√ß√£o da variabilidade do espa√ßo de features. Note que dever√° normalizar as features usando o z-score. Quantas vari√°veis dever√° usar para explicar 75% do feature set? 
# Indique como poderia obter as features relativas a esta compress√£o e exemplifique para um instante √† sua escolha.
# Indique as vantagens e as limita√ß√µes desta abordagem. 
# üñÆ Desenvolva o c√≥digo necess√°rio para implementar o Fisher feature Score e o ReliefF.
# üñé Indentifique as 10 melhores features de acordo com o Fisher Score e o ReliefF.
# Indique como poderia obter as features relativas a esta compress√£o e exemplifique para um instante √† sua escolha.
# Indique as vantagens e as limita√ß√µes desta abordagem. 


# %%
