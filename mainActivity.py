# A . Elabora√ß√£o de um conjunto de scripts e fun√ß√µes em Python, NumPy e SciPy para realizar as tarefas de prepara√ß√£o dos dados e Feature Engineering 

# X Crie um script e grave-o com o nome ‚ÄòmainActivity.py‚Äô. Este script ser√° utilizado na chamada de todas as fun√ß√µes indicadas abaixo.

# %%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
print("Ambiente configurado com sucesso!")
print(f"NumPy version: {np.__version__}")
print(f"Pandas version: {pd.__version__}")


# Descarregue os dados do site https://github.com/spl-icsforth/FORTH_TRACE_DATASET. 
# üñÆ Elabore uma rotina que carregue os dados relativos a um indiv√≠duo e os devolva num Array NumPy. 


# Cada ficheiro CSV segue o formato seguinte:

# Column1: Device ID
# Column2: accelerometer x
# Column3: accelerometer y
# Column4: accelerometer z
# Column5: gyroscope x
# Column6: gyroscope y
# Column7: gyroscope z
# Column8: magnetometer x
# Column9: magnetometer y
# Column10: magnetometer z
# Column11: Timestamp
# Column12: Activity Label

# Table 1: LOCATIONS
# 1 Left Wrist
# 2 Right Wrist
# 3 Torso
# 4 Right Thigh
# 5 Left Ankle

# Table 2: ACTIVITY LABELS
# (Arrows (->) indicate transitions between activities)

# 1 stand
# 2 sit
# 3 sit and talk
# 4 walk
# 5 walk and talk
# 6 climb stairs (up/down)
# 7 climb stairs (up/down) and talk
# 8 stand -> sit
# 9 sit -> stand
# 10 stand -> sit and talk
# 11 sit and talk -> stand
# 12 stand -> walk
# 13 walk -> stand
# 14 stand -> climb stairs (up/down), stand -> climb stairs (up/down) and talk
# 15 climb stairs (up/down) -> walk
# 16 climb stairs (up/down) and talk -> walk and talk


# path: ./FORTH_TRACE_DATASET/part0

# %%
def load_data(file_path):
	# Carregar os dados do ficheiro CSV para um DataFrame do Pandas
	df = pd.read_csv(file_path)
	df.columns = ['Device ID', 'accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'mag_x', 'mag_y', 'mag_z', 'Timestamp', 'Activity Label']
	# Converter o DataFrame para um Array NumPy
	# data_array = df.to_numpy()
	return df

# %%
# Carregar os dados de um indiv√≠duo (exemplo)
file_path = './FORTH_TRACE_DATASET/part0/part0dev1.csv'  # Substitua pelo caminho do

df = load_data(file_path)
# add headers
df.tail()


# %%
# Carregar todos os dados de um participante
base_path='./FORTH_TRACE_DATASET/'

def load_all_data(participant_id):
	df_final = pd.DataFrame()

	for part in range(1, 6):  # part1 a part5
		part_folder = f'part{participant_id}'
		file_path = f'{base_path}{part_folder}/{part_folder}dev{part}.csv'
		try:
			df = load_data(file_path)
			df_final = pd.concat([df_final, df], ignore_index=True)
		except FileNotFoundError:
			pass
	return df_final

# example
df_all = load_all_data(0)
print(f"Total de amostras carregadas: {len(df_all)}")
# df_all.tail()

# %%
# Carregar em um s√≥ dataframe todos os participantes de 0 a 14

def load_all_participants():
	df_final = pd.DataFrame()

	for participant_id in range(0, 15):  # part0 a part14
		df_participant = load_all_data(participant_id)
		# Criar coluna 'Participant ID' e definir como primeira coluna
		df_participant['Participant ID'] = participant_id
		cols = df_participant.columns.tolist()
		cols = ['Participant ID'] + [col for col in cols if col != 'Participant ID']
		df_participant = df_participant[cols]

		df_final = pd.concat([df_final, df_participant], ignore_index=True)
	return df_final

# example
df_all_participants = load_all_participants()
print(f"Total de amostras carregadas de todos os participantes: {len(df_all_participants)}")

# %%
df_all_participants.tail()

# %%
df_all_participants.head()
# An√°lise e tratamento de Outliers: o objectivo ser√° identificar e tratar outliers no dataset usando diferentes abordagens univari√°vel e multivari√°vel.  Para o efeito iremos os m√≥dulos dos vectores acelera√ß√£o, girosc√≥pio e magnet√≥metro. Seja 

# o vector acelera√ß√£o, girosc√≥pio e magnet√≥metro. O respectivo m√≥dulo √© determinado recorrendo:

# üñÆ Elabore uma rotina que apresente simultaneamente o boxplot de cada atividade (coluna 12 ‚Äì eixo horizontal)  relativo a todos os sujeitos e a uma das seguintes vari√°veis transformadas: m√≥dulo do vector de acelera√ß√£o, m√≥dulo do vector de girosc√≥pio e m√≥dulo do vector de magnet√≥metro). Sugere-se o uso da biblioteca matplotlib. 
# üñé Analise e comente a densidade de Outliers existentes no dataset transformado, isto √©, nos m√≥dulos dos vectores acelera√ß√£o, girosc√≥pio e magnet√≥metro para cada atividade. Observe que a densidade √© determinada recorrendo

# em que no √© o n√∫mero de pontos classificados como outliers e nr √© o n√∫mero total de pontos.
# üñÆ Escreva uma rotina que receba um Array de amostras de uma vari√°vel e identifique os outliers usando o teste Z-Score para um k vari√°vel (par√¢metro de entrada).
# üñé Usando o Z-score implementado assinale todos as amostras consideradas outliers nos m√≥dulos dos vectores de acelera√ß√£o, girosc√≥pio e magnet√≥metro. Apresente plots em que estes pontos surgem a vermelho enquanto os restantes surgem a vermelho. Use k=3, 3.5 e 4.
# üñé Compare e discuta os resultados obtidos em 3.1 e 3.4.
# üñÆ Elabore uma rotina que implemente o algoritmo K-means para n (valor de entrada) clusters.
# üñé Determine os outliers no dataset transformado usando o  k-means. Experimente k clusters igual ao n√∫mero de labels e compare com os resultados obtidos em 3.4. Ilustre graficamente os resultados usando plots 3D.  
# B√≥nus: poder√° realizar um estudo an√°logo usando o algoritmo DBSCAN (sugere-se que recorra √† biblioteca sklearn) 

# üñÆ Implemente uma rotina que injete ouliers com uma densidade igual ou superior a x% nas amostras de vari√°vel fornecida. Para o efeito dever√°:
# A calcular a densidade de outliers existente no Array fornecido com nr pontos; observe que a densidade d √© obtida por

# em que


# Se a densidade d for inferior a x, ent√£o dever√° sortear  (x-d)% dos pontos n√£o outliers de forma aleat√≥ria e para cada ponto selecionado dever√° transform√°-lo tal que
 
# em que Œº e œÉ representam, respectivamente, os valores m√©dio e o desvio padr√£o da amostra,  k √© o limite especificado no ponto 3.3, s‚àà{-1,1} √© uma vari√°vel escolhida de forma aleat√≥ria usando uma distribui√ß√£o uniforme e q √© uma vari√°vel aleat√≥ria uniforme no intervalo q ‚àà [0,z[ em que z √© a amplitude m√°xima do outlier relativamente a Œº¬±kœÉ.

# üñÆ Elabore uma rotina que determine o modelo linear de ordem p. Para o efeito, a sua rotina dever√° receber n amostras de treino de um vector de dimens√£o p , isto √©, (xi,1, xi,2, xi,2, ... , xi,p) e a respectiva sa√≠da yi. A sua rotina dever√° determinar o melhor vector de pesos Œ≤ tal que 

# üñé Determine o modelo linear para o m√≥dulo acelera√ß√£o usando uma janela com p valores anteriores. Usando a rotina desenvolvida no ponto 3.9 injete 10% de outliers no m√≥dulo da acelera√ß√£o. Elimine esses outliers e substitua-os pelos valores previstos pelo modelo linear. Analise o erro de predi√ß√£o apresentando i) a distribui√ß√£o do erro e ii) exemplos de plots contendo o valor previsto e real. Determine o melhor p para o seu modelo.
# üñé Repita 3.10 usando uma janela de dimens√£o p centrada no instante a prever. Dever√° usar n√£o s√≥ os p/2 valores anteriores e seguintes da vari√°vel que pretende prever bem como das restantes vari√°veis dispon√≠veis (m√≥dulos dispon√≠veis). Compare com os resultados obtidos em 3.10.

# Extra√ß√£o de informa√ß√£o caracter√≠stica: o objectivo ser√° comprimir o espa√ßo do problema, extraindo informa√ß√£o caracter√≠stica discriminante que permita implementar solu√ß√µes eficazes do problema de classifica√ß√£o.

# üñé Usando as vari√°veis aplicadas na al√≠nea 3.1, determine a signific√¢ncia estat√≠sticas dos seus valores m√©dios na diferentes atividades. Observe que poder√° aferir a gaussianidade da distribui√ß√£o usando, por exemplo, o teste Kolmogorov-Smirnov (vide documenta√ß√£o do SciPy). Para rever a escolha de testes estat√≠sticos sugere-se a refer√™ncia: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881615/ .   Comente.
# üñÆ Desenvolva as rotinas necess√°rias √† extra√ß√£o do feature set temporal e espectral sugerido no artigo  https://pdfs.semanticscholar.org/8522/ce2bfce1ab65b133e411350478183e79fae7.pdf. Para o efeito dever√°:
# Ler o artigo e identificar o conjunto de features temporais e espectrais identificadas por estes autores
# Para cada feature dever√° elaborar uma rotina para a respectiva extra√ß√£o 
# Usando as rotinas elaboradas no item anterior, dever√° escrever o c√≥digo necess√°rio para extrair o vetor de features em cada instante.  
# Nota: Poder√° usar as bibliotecas NumPy e SciPy. Qualquer outra biblioteca dever√° ser identificada. 

# üñÆ Desenvolva o c√≥digo necess√°rio para implementar o PCA de um feature set.
# üñé Determine a import√¢ncia de cada vetor na explica√ß√£o da variabilidade do espa√ßo de features. Note que dever√° normalizar as features usando o z-score. Quantas vari√°veis dever√° usar para explicar 75% do feature set? 
# Indique como poderia obter as features relativas a esta compress√£o e exemplifique para um instante √† sua escolha.
# Indique as vantagens e as limita√ß√µes desta abordagem. 
# üñÆ Desenvolva o c√≥digo necess√°rio para implementar o Fisher feature Score e o ReliefF.
# üñé Indentifique as 10 melhores features de acordo com o Fisher Score e o ReliefF.
# Indique como poderia obter as features relativas a esta compress√£o e exemplifique para um instante √† sua escolha.
# Indique as vantagens e as limita√ß√µes desta abordagem. 


# %%
